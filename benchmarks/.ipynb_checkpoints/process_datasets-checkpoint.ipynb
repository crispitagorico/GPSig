{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_files = sorted(glob.glob('./datasets/*.mat'), key=lambda x: x.lower())\n",
    "datasets = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset: ArabicDigits (1/16)\n",
      "- n_train : 6600\n",
      "- n_test : 2200\n",
      "- n_classes : 10\n",
      "- l_examples : 4 - 93\n",
      "- n_features : 13\n",
      "\n",
      "Processing dataset: AUSLAN (2/16)\n",
      "- n_train : 1140\n",
      "- n_test : 1425\n",
      "- n_classes : 95\n",
      "- l_examples : 45 - 136\n",
      "- n_features : 22\n",
      "\n",
      "Processing dataset: CharacterTrajectories (3/16)\n",
      "- n_train : 300\n",
      "- n_test : 2558\n",
      "- n_classes : 20\n",
      "- l_examples : 109 - 205\n",
      "- n_features : 3\n",
      "\n",
      "Processing dataset: CMUsubject16 (4/16)\n",
      "- n_train : 29\n",
      "- n_test : 29\n",
      "- n_classes : 2\n",
      "- l_examples : 127 - 580\n",
      "- n_features : 62\n",
      "\n",
      "Processing dataset: DigitShapes (5/16)\n",
      "- n_train : 24\n",
      "- n_test : 16\n",
      "- n_classes : 4\n",
      "- l_examples : 30 - 98\n",
      "- n_features : 2\n",
      "\n",
      "Processing dataset: ECG (6/16)\n",
      "- n_train : 100\n",
      "- n_test : 100\n",
      "- n_classes : 2\n",
      "- l_examples : 39 - 152\n",
      "- n_features : 2\n",
      "\n",
      "Processing dataset: JapaneseVowels (7/16)\n",
      "- n_train : 270\n",
      "- n_test : 370\n",
      "- n_classes : 9\n",
      "- l_examples : 7 - 29\n",
      "- n_features : 12\n",
      "\n",
      "Processing dataset: KickvsPunch (8/16)\n",
      "- n_train : 16\n",
      "- n_test : 10\n",
      "- n_classes : 2\n",
      "- l_examples : 274 - 841\n",
      "- n_features : 62\n",
      "\n",
      "Processing dataset: LIBRAS (9/16)\n",
      "- n_train : 180\n",
      "- n_test : 180\n",
      "- n_classes : 15\n",
      "- l_examples : 45 - 45\n",
      "- n_features : 2\n",
      "\n",
      "Processing dataset: NetFlow (10/16)\n",
      "- n_train : 803\n",
      "- n_test : 534\n",
      "- n_classes : 2\n",
      "- l_examples : 50 - 997\n",
      "- n_features : 4\n",
      "\n",
      "Processing dataset: PEMS (11/16)\n",
      "- n_train : 267\n",
      "- n_test : 173\n",
      "- n_classes : 7\n",
      "- l_examples : 144 - 144\n",
      "- n_features : 963\n",
      "\n",
      "Processing dataset: PenDigits (12/16)\n",
      "- n_train : 300\n",
      "- n_test : 10692\n",
      "- n_classes : 10\n",
      "- l_examples : 8 - 8\n",
      "- n_features : 2\n",
      "\n",
      "Processing dataset: Shapes (13/16)\n",
      "- n_train : 18\n",
      "- n_test : 12\n",
      "- n_classes : 3\n",
      "- l_examples : 52 - 98\n",
      "- n_features : 2\n",
      "\n",
      "Processing dataset: UWave (14/16)\n",
      "- n_train : 896\n",
      "- n_test : 3582\n",
      "- n_classes : 8\n",
      "- l_examples : 315 - 315\n",
      "- n_features : 3\n",
      "\n",
      "Processing dataset: Wafer (15/16)\n",
      "- n_train : 298\n",
      "- n_test : 896\n",
      "- n_classes : 2\n",
      "- l_examples : 104 - 198\n",
      "- n_features : 6\n",
      "\n",
      "Processing dataset: WalkvsRun (16/16)\n",
      "- n_train : 28\n",
      "- n_test : 16\n",
      "- n_classes : 2\n",
      "- l_examples : 128 - 1918\n",
      "- n_features : 62\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, mat_file in enumerate(mat_files):\n",
    "    dataset = os.path.basename(mat_file).rstrip('.mat')\n",
    "    print('Processing dataset: {} ({}/{})'.format(dataset, i+1, len(mat_files)))\n",
    "    datasets[dataset] = {}\n",
    "    \n",
    "    mat = loadmat(mat_file)\n",
    "    X_train, y_train, X_test, y_test = np.squeeze(mat['X_train']), np.squeeze(mat['y_train']), np.squeeze(mat['X_test']), np.squeeze(mat['y_test'])\n",
    "    \n",
    "    assert len(X_train) == len(y_train)\n",
    "    assert len(X_test) == len(y_test)\n",
    "    num_train, num_test = len(X_train), len(X_test)\n",
    "    datasets[dataset]['n_train'] = num_train\n",
    "    datasets[dataset]['n_test'] = num_test\n",
    "    print('- n_train : {}'.format(num_train))\n",
    "    print('- n_test : {}'.format(num_test))\n",
    "    \n",
    "    assert all(np.unique(y_train) == np.unique(y_test))\n",
    "    num_classes = np.unique(y_train).size\n",
    "    datasets[dataset]['n_classes'] = num_classes\n",
    "    print('- n_classes : {}'.format(num_classes))\n",
    "    \n",
    "    len_examples = [x.shape[0] for x in X_train] + [x.shape[0] for x in X_test]\n",
    "    len_min, len_max = min(len_examples), max(len_examples)\n",
    "    datasets[dataset]['l_min'] = len_min\n",
    "    datasets[dataset]['l_max'] = len_max\n",
    "    print('- l_examples : {} - {}'.format(len_min, len_max))\n",
    "    \n",
    "    num_features = [x.shape[1] for x in X_train] + [x.shape[1] for x in X_test]\n",
    "    assert all([x == num_features[0] for x in num_features])\n",
    "    num_features = num_features[0]\n",
    "    datasets[dataset]['n_features'] = num_features\n",
    "    print('- n_features : {}'.format(num_features))\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./datasets.json', 'w') as f:\n",
    "    json.dump(datasets, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU-Havok",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
